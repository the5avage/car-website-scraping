{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdc55e48",
   "metadata": {},
   "source": [
    "### Test: BERT large uncased\n",
    "\n",
    "Model reference and usage description: https://huggingface.co/google-bert/bert-large-uncased\n",
    "\n",
    "Example usage: Feeding an input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bd9346a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-large-uncased\")\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5381bad1",
   "metadata": {},
   "source": [
    "BERT does transform the input text / input tokens into the vector space.  \n",
    "The `last_hidden_state` contains the final embeddings for each token in the sequence.\n",
    "\n",
    "The pooler applies a fully connected layer to the `[CLS]` token to obtain a condensed representation of the entire sequence.  \n",
    "This condensed representation can be used in a classification task, as this single vector now represents the whole input sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b645aae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Hidden State Shape: torch.Size([1, 12, 1024])\n",
      "Pooler Output Shape: torch.Size([1, 1024])\n",
      "Tokens: ['[CLS]', 'replace', 'me', 'by', 'any', 'text', 'you', \"'\", 'd', 'like', '.', '[SEP]']\n",
      "Embedding of first token (CLS): tensor([-0.1534, -0.9412, -0.6168,  ..., -0.7690, -0.0030,  0.2449],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Embedding of the first word token: tensor([-0.5923, -0.7163, -0.9268,  ...,  0.4954,  0.4566,  0.0285],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Pooler Output (CLS after pooling): tensor([[-0.9995, -0.9970,  1.0000,  ..., -1.0000,  0.9944, -0.9978]],\n",
      "       grad_fn=<TanhBackward0>)\n"
     ]
    }
   ],
   "source": [
    "last_hidden_state = output.last_hidden_state\n",
    "pooler_output = output.pooler_output\n",
    "\n",
    "# Print the shapes of the outputs\n",
    "print(\"Last Hidden State Shape:\", last_hidden_state.shape) # Shape: [batch_size, sequence_length, hidden_size]\n",
    "print(\"Pooler Output Shape:\", pooler_output.shape) # Shape: [batch_size, hidden_size]\n",
    "\n",
    "# Decode the tokens back to see how BERT splits the input\n",
    "tokens = tokenizer.convert_ids_to_tokens(encoded_input['input_ids'][0])\n",
    "print(f\"Tokens: {tokens}\")\n",
    "print(f\"Embedding of first token (CLS): {last_hidden_state[0][0]}\")  # CLS token embedding\n",
    "print(f\"Embedding of the first word token: {last_hidden_state[0][1]}\")  # First word's token embedding\n",
    "\n",
    "# Embedding of the CLS token after pooling\n",
    "print(f\"Pooler Output (CLS after pooling): {pooler_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53e41cd",
   "metadata": {},
   "source": [
    "Explanation:  \n",
    "batch_size: Number of model inputs. If multiple sentences are processed in parallel, the batch size will be greater than 1.  \n",
    "sequence_length: number of tokens in a given input sentence or text. BERT has a maximum sequence length of 512 tokens !!!  \n",
    "hidden_size: fixed number of neurons in each layer. `bert-base-uncased` has 768, `bert-large-uncased` has 1024 neurons per layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55096b94",
   "metadata": {},
   "source": [
    "### Test: Sentence-BERT (SBERT)\n",
    "This version of BERT is optimized for comparing sentence similarity or finding related pairs.\n",
    "\n",
    "requirement: `pip3 install -U sentence-transformers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "046effa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score: 0.7127\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2', device=device)\n",
    "\n",
    "# Texts\n",
    "short_text = (\n",
    "    \"I'm looking for a white diesel van with automatic transmission, registered recently, \"\n",
    "    \"less than 30,000 km driven, and EURO 6 emission class.\"\n",
    ")\n",
    "\n",
    "long_text = \"\"\"\n",
    "Information:\n",
    "Category: Van / minibus, 5 door. Engine type: Diesel. Fuel type: Diesel. Emission class: EURO 6. \n",
    "CO2 emissions: 173 g/km (combined). Power output: 110 KW / 150 PS. First registration: 12.2023. \n",
    "KBA Key Manufacturer: 0603. KBA Key Type: CQJ. VIN: WV2ZZZST2RH******. Transmission: Automatic. \n",
    "Colour: white (Sonderlackierung Candy-weiss). Read mileage: 21,800 Kilometres. \n",
    "Owners: 1. Location: D-73. Vehicle release: 3 working days after payment.\n",
    "\"\"\"\n",
    "\n",
    "# Embeddings\n",
    "short_emb = model.encode(short_text, convert_to_tensor=True)\n",
    "long_emb = model.encode(long_text, convert_to_tensor=True)\n",
    "\n",
    "# Cosine similarity\n",
    "score = util.cos_sim(short_emb, long_emb).item()\n",
    "print(f\"Similarity score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345dd254",
   "metadata": {},
   "source": [
    "Test: Checking the cosine similarity for different car texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3585b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score (short_text_1): 0.7127\n",
      "Similarity score (short_text_2): 0.6525\n",
      "Similarity score (short_text_3): 0.3093\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2', device=device)\n",
    "\n",
    "# Text\n",
    "long_text = \"\"\"\n",
    "Information:\n",
    "Category: Van / minibus, 5 door. Engine type: Diesel. Fuel type: Diesel. Emission class: EURO 6. \n",
    "CO2 emissions: 173 g/km (combined). Power output: 110 KW / 150 PS. First registration: 12.2023. \n",
    "KBA Key Manufacturer: 0603. KBA Key Type: CQJ. VIN: WV2ZZZST2RH******. Transmission: Automatic. \n",
    "Colour: white (Sonderlackierung Candy-weiss). Read mileage: 21,800 Kilometres. \n",
    "Owners: 1. Location: D-73. Vehicle release: 3 working days after payment.\n",
    "\"\"\"\n",
    "\n",
    "# 1. Matching query from before\n",
    "short_text_1 = (\n",
    "    \"I'm looking for a white diesel van with automatic transmission, registered recently, \"\n",
    "    \"less than 30,000 km driven, and EURO 6 emission class.\"\n",
    ")\n",
    "\n",
    "# 2. Close wording, but doesn't match key facts (manual, petrol, older, wrong emissions)\n",
    "short_text_2 = (\n",
    "    \"I'm searching for a white petrol van with manual transmission, EURO 5 emissions, \"\n",
    "    \"and around 80,000 kilometers mileage.\"\n",
    ")\n",
    "\n",
    "# 3. Completely different car (sports car, different body, color, purpose, etc.)\n",
    "short_text_3 = (\n",
    "    \"I'm interested in a red convertible sports car with over 300 horsepower and leather seats.\"\n",
    ")\n",
    "\n",
    "# Encode all texts\n",
    "long_emb = model.encode(long_text, convert_to_tensor=True)\n",
    "queries = [short_text_1, short_text_2, short_text_3]\n",
    "query_embs = model.encode(queries, convert_to_tensor=True)\n",
    "\n",
    "# Compare each short query to the long description\n",
    "for i, emb in enumerate(query_embs):\n",
    "    sim = util.cos_sim(emb, long_emb).item()\n",
    "    print(f\"Similarity score (short_text_{i+1}): {sim:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
