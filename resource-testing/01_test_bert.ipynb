{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdc55e48",
   "metadata": {},
   "source": [
    "### Test: BERT large uncased\n",
    "\n",
    "Model reference and usage description: https://huggingface.co/google-bert/bert-large-uncased\n",
    "\n",
    "Example usage: Feeding an input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bd9346a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-large-uncased\")\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5381bad1",
   "metadata": {},
   "source": [
    "BERT does transform the input text / input tokens into the vector space.  \n",
    "The `last_hidden_state` contains the final embeddings for each token in the sequence.\n",
    "\n",
    "The pooler applies a fully connected layer to the `[CLS]` token to obtain a condensed representation of the entire sequence.  \n",
    "This condensed representation can be used in a classification task, as this single vector now represents the whole input sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b645aae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Hidden State Shape: torch.Size([1, 12, 1024])\n",
      "Pooler Output Shape: torch.Size([1, 1024])\n",
      "Tokens: ['[CLS]', 'replace', 'me', 'by', 'any', 'text', 'you', \"'\", 'd', 'like', '.', '[SEP]']\n",
      "Embedding of first token (CLS): tensor([-0.1534, -0.9412, -0.6168,  ..., -0.7690, -0.0030,  0.2449],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Embedding of the first word token: tensor([-0.5923, -0.7163, -0.9268,  ...,  0.4954,  0.4566,  0.0285],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Pooler Output (CLS after pooling): tensor([[-0.9995, -0.9970,  1.0000,  ..., -1.0000,  0.9944, -0.9978]],\n",
      "       grad_fn=<TanhBackward0>)\n"
     ]
    }
   ],
   "source": [
    "last_hidden_state = output.last_hidden_state\n",
    "pooler_output = output.pooler_output\n",
    "\n",
    "# Print the shapes of the outputs\n",
    "print(\"Last Hidden State Shape:\", last_hidden_state.shape) # Shape: [batch_size, sequence_length, hidden_size]\n",
    "print(\"Pooler Output Shape:\", pooler_output.shape) # Shape: [batch_size, hidden_size]\n",
    "\n",
    "# Decode the tokens back to see how BERT splits the input\n",
    "tokens = tokenizer.convert_ids_to_tokens(encoded_input['input_ids'][0])\n",
    "print(f\"Tokens: {tokens}\")\n",
    "print(f\"Embedding of first token (CLS): {last_hidden_state[0][0]}\")  # CLS token embedding\n",
    "print(f\"Embedding of the first word token: {last_hidden_state[0][1]}\")  # First word's token embedding\n",
    "\n",
    "# Embedding of the CLS token after pooling\n",
    "print(f\"Pooler Output (CLS after pooling): {pooler_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53e41cd",
   "metadata": {},
   "source": [
    "Explanation:  \n",
    "batch_size: Number of model inputs. If multiple sentences are processed in parallel, the batch size will be greater than 1.  \n",
    "sequence_length: number of tokens in a given input sentence or text. BERT has a maximum sequence length of 512 tokens !!!  \n",
    "hidden_size: fixed number of neurons in each layer. `bert-base-uncased` has 768, `bert-large-uncased` has 1024 neurons per layer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
