{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigating to: https://autobid.de/en/search-results?sortingType=auctionStartDate-ASCENDING\n",
      "Found 173 total links\n",
      "\n",
      "--- Extracting content from: https://bmw.autobid.de/en/item/mini-cooper-steptronic-classic-trim-3106255/details ---\n",
      "\n",
      "--- Extracting content from: https://autobid.de/en/item/bmw-baureihe-3-touring-320-d-xdrive-m-sport-connected-professional-uvp-82-630-01-3098344/details ---\n",
      "\n",
      "--- Extracting content from: https://bmw.autobid.de/en/item/bmw-118i-m-sport-3106256/details ---\n",
      "\n",
      "--- Extracting content from: https://autobid.de/en/item/vw-multivan-edition-dsg-easy-open-advanced-uvp-73-483-69-3099376/details ---\n",
      "\n",
      "--- Extracting content from: https://bmw.autobid.de/en/item/bmw-330e-xdrive-touring-sport-automatic-m-sport-3106257/details ---\n",
      "\n",
      "--- Extracting content from: https://autobid.de/en/item/bmw-baureihe-2-active-tourer-218-i-m-sport-connected-professional-uvp-54-400-03-3106595/details ---\n",
      "\n",
      "--- Extracting content from: https://bmw.autobid.de/en/item/opel-corsa-1-2-edition-3106267/details ---\n",
      "\n",
      "--- Extracting content from: https://autobid.de/en/item/vw-touran-comfortline-bmt-start-stopp-dsg-easy-open-uvp-53-744-99-3108578/details ---\n",
      "\n",
      "--- Extracting content from: https://bmw.autobid.de/en/item/bmw-330d-touring-sport-automatic-m-sport-3106269/details ---\n",
      "\n",
      "--- Extracting content from: https://autobid.de/en/item/bmw-baureihe-2-active-tourer-218-i-connected-professional-uvp-47-340-02-3108194/details ---\n",
      "\n",
      "--- Extracting content from: https://bmw.autobid.de/en/item/bmw-x3-xdrive20d-steptronic-advantage-3106270/details ---\n",
      "\n",
      "--- Extracting content from: https://autobid.de/en/item/bmw-baureihe-1-lim-118-i-m-sport-uvp-48-860-01-3109425/details ---\n",
      "\n",
      "--- Extracting content from: https://bmw.autobid.de/en/item/bmw-m440i-xdrive-cabrio-sport-automatic-m-sport-3106274/details ---\n",
      "\n",
      "--- Extracting content from: https://autobid.de/en/item/bmw-baureihe-x1-23-d-xdrive-xline-connected-professional-uvp-66-920-01-3110316/details ---\n",
      "\n",
      "--- Extracting content from: https://bmw.autobid.de/en/item/mercedes-benz-glc-250-coupe-4matic-9g-tronic-3106275/details ---\n",
      "\n",
      "--- Extracting content from: https://autobid.de/en/item/bmw-baureihe-3-touring-320-d-xdrive-m-sport-connected-professional-uvp-81-629-99-3108579/details ---\n",
      "\n",
      "--- Extracting content from: https://bmw.autobid.de/en/item/bmw-220i-active-tourer-steptronic-advantage-3106277/details ---\n",
      "\n",
      "--- Extracting content from: https://autobid.de/en/item/vw-touran-comfortline-bmt-start-stopp-dsg-easy-open-uvp-49-870-00-3108188/details ---\n",
      "\n",
      "--- Extracting content from: https://bmw.autobid.de/en/item/bmw-520d-xdrive-touring-steptronic-3106278/details ---\n",
      "\n",
      "--- Extracting content from: https://autobid.de/en/item/bmw-baureihe-4-gran-coupe-420-d-xdrive-m-sport-connected-professional-uvp-77-489-98-3098983/details ---\n",
      "\n",
      "✅ Data saved to vehicles_data.json\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "class ArticleLinkParser:\n",
    "    def __init__(self, headless=False, delay_range=(1, 3)):\n",
    "        \"\"\"\n",
    "        Initialize the parser with browser settings\n",
    "\n",
    "        Args:\n",
    "            headless (bool): Whether to run browser in headless mode\n",
    "            delay_range (tuple): Min and max delay in seconds between actions\n",
    "        \"\"\"\n",
    "        self.delay_range = delay_range\n",
    "        self.driver = None\n",
    "        self.setup_driver(headless)\n",
    "\n",
    "    def setup_driver(self, headless=False):\n",
    "        \"\"\"Setup Chrome driver with human-like settings\"\"\"\n",
    "        chrome_options = Options()\n",
    "\n",
    "        if headless:\n",
    "            chrome_options.add_argument(\"--headless\")\n",
    "\n",
    "        # Enhanced anti-detection measures\n",
    "        chrome_options.add_argument(\"--no-sandbox\")\n",
    "        chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "        chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "        chrome_options.add_argument(\"--disable-extensions\")\n",
    "        chrome_options.add_argument(\"--disable-plugins\")\n",
    "        chrome_options.add_argument(\"--disable-images\")  # Faster loading\n",
    "        chrome_options.add_argument(\"--disable-javascript\")  # Remove if JS is needed\n",
    "        chrome_options.add_argument(\"--disable-gpu\")\n",
    "        chrome_options.add_argument(\"--disable-web-security\")\n",
    "        chrome_options.add_argument(\"--allow-running-insecure-content\")\n",
    "        chrome_options.add_argument(\"--disable-features=VizDisplayCompositor\")\n",
    "\n",
    "        # Remove automation indicators\n",
    "        chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "        chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "\n",
    "        # More realistic user agent (latest Chrome)\n",
    "        chrome_options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "\n",
    "        # Additional prefs to avoid detection\n",
    "        prefs = {\n",
    "            \"profile.default_content_setting_values\": {\n",
    "                \"notifications\": 2,\n",
    "                \"media_stream\": 2,\n",
    "                \"geolocation\": 2\n",
    "            },\n",
    "            \"profile.managed_default_content_settings\": {\n",
    "                \"images\": 2  # Block images for faster loading\n",
    "            }\n",
    "        }\n",
    "        chrome_options.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "        self.driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "        # Execute script to remove webdriver traces\n",
    "        self.driver.execute_script(\"\"\"\n",
    "            Object.defineProperty(navigator, 'webdriver', {get: () => undefined});\n",
    "            Object.defineProperty(navigator, 'plugins', {get: () => [1, 2, 3, 4, 5]});\n",
    "            Object.defineProperty(navigator, 'languages', {get: () => ['en-US', 'en']});\n",
    "            window.chrome = {runtime: {}};\n",
    "        \"\"\")\n",
    "\n",
    "        # Set window size to common resolution\n",
    "        self.driver.set_window_size(1366, 768)\n",
    "\n",
    "    def human_delay(self, min_delay=None, max_delay=None):\n",
    "        \"\"\"Add random delay to mimic human behavior\"\"\"\n",
    "        if min_delay is None:\n",
    "            min_delay = self.delay_range[0]\n",
    "        if max_delay is None:\n",
    "            max_delay = self.delay_range[1]\n",
    "\n",
    "        delay = random.uniform(min_delay, max_delay)\n",
    "        time.sleep(delay)\n",
    "\n",
    "    def scroll_page(self, scrolls=3):\n",
    "        \"\"\"Scroll the page naturally like a human would\"\"\"\n",
    "        for i in range(scrolls):\n",
    "            # Scroll down\n",
    "            scroll_height = random.randint(300, 800)\n",
    "            self.driver.execute_script(f\"window.scrollBy(0, {scroll_height});\")\n",
    "            self.human_delay(0.5, 1.5)\n",
    "\n",
    "        # Scroll back to top\n",
    "        self.driver.execute_script(\"window.scrollTo(0, 0);\")\n",
    "        self.human_delay(1, 2)\n",
    "\n",
    "    def get_all_links(self, url):\n",
    "        \"\"\"\n",
    "        Navigate to URL and get all links on the page\n",
    "\n",
    "        Args:\n",
    "            url (str): The URL to parse\n",
    "\n",
    "        Returns:\n",
    "            list: All links found on the page\n",
    "        \"\"\"\n",
    "        print(f\"Navigating to: {url}\")\n",
    "        self.driver.get(url)\n",
    "\n",
    "        # Wait for page to load\n",
    "        WebDriverWait(self.driver, 10).until(\n",
    "            EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    "        )\n",
    "\n",
    "        # Human-like behavior: scroll through page\n",
    "        self.scroll_page()\n",
    "\n",
    "        # Find all links\n",
    "        link_elements = self.driver.find_elements(By.TAG_NAME, \"a\")\n",
    "\n",
    "        links = []\n",
    "        for element in link_elements:\n",
    "            href = element.get_attribute(\"href\")\n",
    "            text = element.text.strip()\n",
    "\n",
    "            if href:\n",
    "                # Convert relative URLs to absolute\n",
    "                absolute_url = urljoin(url, href)\n",
    "                links.append({\n",
    "                    'url': absolute_url,\n",
    "                    'text': text,\n",
    "                    'element': element\n",
    "                })\n",
    "\n",
    "        print(f\"Found {len(links)} total links\")\n",
    "        return links\n",
    "\n",
    "    def filter_item_links(self, links):\n",
    "        \"\"\"\n",
    "        Filter links to get only item links with #content and convert to /details\n",
    "\n",
    "        Args:\n",
    "            links (list): List of all links\n",
    "\n",
    "        Returns:\n",
    "            list: Filtered item links with #content replaced by /details\n",
    "        \"\"\"\n",
    "        item_links = []\n",
    "        seen_urls = set()  # To avoid duplicates\n",
    "\n",
    "        for link in links:\n",
    "            url = link['url']\n",
    "            text = link['text']\n",
    "\n",
    "            # Check if URL contains \"/item/\" and ends with \"#content\"\n",
    "            if \"/item/\" in url and url.endswith(\"#content\"):\n",
    "                # Replace #content with /details\n",
    "                details_url = url.replace(\"#content\", \"/details\")\n",
    "\n",
    "                # Avoid duplicates (same item might have multiple links)\n",
    "                if details_url not in seen_urls:\n",
    "                    seen_urls.add(details_url)\n",
    "                    item_links.append(details_url)\n",
    "\n",
    "        return item_links\n",
    "\n",
    "    def get_item_links(self, url):\n",
    "        \"\"\"\n",
    "        Get all item links from the page\n",
    "\n",
    "        Args:\n",
    "            url (str): The URL to parse\n",
    "\n",
    "        Returns:\n",
    "            list: Filtered item links\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Get all links first\n",
    "            all_links = self.get_all_links(url)\n",
    "\n",
    "            # Filter for item links\n",
    "            item_links = self.filter_item_links(all_links)\n",
    "\n",
    "            return item_links\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting item links: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    def get_vehicle_soup(self, vehicle_url):\n",
    "        self.human_delay()\n",
    "        self.scroll_page()\n",
    "        self.driver.get(vehicle_url)\n",
    "\n",
    "        return BeautifulSoup(self.driver.page_source, 'html.parser')\n",
    "\n",
    "    def parse_vehicle_details(self, soup):\n",
    "        ausstattung_header = soup.find(lambda tag: tag.name == \"header\" and \"Vehicle extras, add-ons and accessories\" in tag.get_text())\n",
    "\n",
    "        items = []\n",
    "        freetext = \"\"\n",
    "\n",
    "        if ausstattung_header:\n",
    "            ausstattung_list = ausstattung_header.find_next(\"ul\")\n",
    "            if ausstattung_list:\n",
    "                items = [li.get_text(strip=True) for li in ausstattung_list.find_all(\"li\")]\n",
    "            else:\n",
    "                print(\"List not found after header.\")\n",
    "\n",
    "            # Now look for the next <div> after the list — this might be the free text\n",
    "            freetext_div = ausstattung_list.find_next(\"div\") if ausstattung_list else None\n",
    "            if freetext_div:\n",
    "                freetext = freetext_div.get_text(strip=True)\n",
    "            else:\n",
    "                print(\"Freetext div not found.\")\n",
    "        else:\n",
    "            print(\"Header not found.\")\n",
    "\n",
    "        return items, freetext\n",
    "\n",
    "    def parse_table_after_header(self, soup, header_text):\n",
    "        header = soup.find(lambda tag: tag.name == \"header\" and header_text in tag.get_text())\n",
    "        table_data = []\n",
    "\n",
    "        if header:\n",
    "            table = header.find_next(\"table\")\n",
    "            if table:\n",
    "                rows = table.find_all(\"tr\")\n",
    "                for row in rows:\n",
    "                    cols = row.find_all([\"td\", \"th\"])  # In case the table has headers\n",
    "                    row_data = [col.get_text(strip=True) for col in cols]\n",
    "                    table_data.append(row_data)\n",
    "            else:\n",
    "                print(f\"Table not found after header '{header_text}'.\")\n",
    "        else:\n",
    "            print(f\"Header '{header_text}' not found.\")\n",
    "\n",
    "        return table_data\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Close the browser\"\"\"\n",
    "        if self.driver:\n",
    "            self.driver.quit()\n",
    "\n",
    "website_url = \"https://autobid.de/en/search-results?sortingType=auctionStartDate-ASCENDING\"\n",
    "\n",
    "# Initialize parser\n",
    "parser = ArticleLinkParser(headless=False, delay_range=(1, 3))\n",
    "\n",
    "# Get item links\n",
    "item_links = parser.get_item_links(website_url)\n",
    "\n",
    "all_data = {}\n",
    "\n",
    "for item_url in item_links:\n",
    "    print(f\"\\n--- Extracting content from: {item_url} ---\")\n",
    "\n",
    "    vehicle_soup = parser.get_vehicle_soup(item_url)\n",
    "\n",
    "    # Parse sections\n",
    "    information_list = parser.parse_table_after_header(vehicle_soup, \"Information\")\n",
    "    details_list, details_text = parser.parse_vehicle_details(vehicle_soup)\n",
    "\n",
    "    # Convert to dict\n",
    "    information_dict = {}\n",
    "    for pair in information_list:\n",
    "        key = pair[0].rstrip(':')\n",
    "        value = pair[1]\n",
    "        information_dict[key] = value\n",
    "\n",
    "    # Store in the result dict\n",
    "    all_data[item_url] = {\n",
    "        \"information_dict\": information_dict,\n",
    "        \"details_list\": details_list,\n",
    "        \"details_text\": details_text\n",
    "    }\n",
    "\n",
    "# Save to JSON file\n",
    "with open(\"vehicles_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"\\n✅ Data saved to vehicles_data.json\")\n",
    "\n",
    "parser.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
