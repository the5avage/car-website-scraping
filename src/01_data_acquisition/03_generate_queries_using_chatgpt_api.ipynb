{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create queries\n",
    "\n",
    "We want to enable our application user to automatically search new entries on the autobid platform using natural language. Thus, we need to fine-tune a model to handle search queries like: \"I am looking for a quite new red sports car.\" We generated the queries (after multiple other different ideas and attempts) using the ChatGPT API with GPT-4 (as those queries showed the highest quality out of all our trials).\n",
    "\n",
    "At the end, we got for about 550 of our 2500 scraped vehicle information texts queries (for a 30$ investement). For each of the 550 vehicle texts, we generated 10 queries - 5 matching \"true\" cases and 5 unmatching \"false\" queries per text, which gave us a total of about 5500 queries to fine-tune our BERT models on.\n",
    "\n",
    "Step 1: Load scraped vehicle information from the yaml file, as our queries are going to match the vehicles (or contradict them partly for false cases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "def get_vehicles_as_dict(file_path):\n",
    "    \"\"\"\n",
    "    Parse YAML file and return a dictionary with URLs as keys and YAML text as values.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the YAML file\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary where keys are URLs and values are YAML text for each vehicle\n",
    "    \"\"\"\n",
    "    # Load the YAML file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = yaml.safe_load(file)\n",
    "\n",
    "    # Create dictionary with URLs as keys and YAML text as values\n",
    "    vehicles_dict = {}\n",
    "    for url, vehicle_info in data.items():\n",
    "        # Convert just the vehicle info (not including the URL) to YAML text\n",
    "        yaml_text = yaml.dump(vehicle_info, default_flow_style=False, allow_unicode=True)\n",
    "        vehicles_dict[url] = yaml_text\n",
    "\n",
    "    return vehicles_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_data_file = \"../../data/final_vehicles_data.yaml\"\n",
    "vehicle_data = get_vehicles_as_dict(vehicle_data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Prompt engineering: Find a prompt combination that works the way that our results are going to become 10 queries, 5 true, 5 false per car, in JSON format. The queries shall sound as natural as possible and refer to our scraped car in different ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant that evaluates search queries based on detailed car descriptions.\n",
    "The user provides vehicle details in structured format. You must generate five realistic search\n",
    "queries that match the car and another five that don't (but aren't absurd), and return them as a\n",
    "JSON object where each key is a query and the value is a boolean indicating whether the query matches\n",
    "the car (true) or not (false). Respond only with the JSON object, nothing else.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"\n",
    "Please create realistic search queries of someone who is searching for a car. Keep in mind that, when searching for a vehicle,\n",
    "they won't already know details like exact read mileage and horse power. Mileage and horse power are important but a car dealer would\n",
    "ask for a broad range. When asking for kilometers, hp or the number of previous owners always pick a specific number\n",
    "(not the one from the text) and ask if the car has more or less of it. Milage is important so some queries should ask if it has more and some if it has less.\n",
    "The same is true for registration date and horsepower/kW.\n",
    "Also try to be specific and put in numbers for details that need them. Something like \"low mileage\" and \"powerful engine\" could be interpreted differently.\n",
    "The search won't contain every detail of the car. Also vary the wording\n",
    "and the chosen details of the search question for the queries and use synonyms for some of them. Make the queries multiple sentences\n",
    "long and detailed. The car dealer has specific requirements.\n",
    "When looking at the car details, the \"information_dict:\" contains the most valuable information about the car.\n",
    "\n",
    "After that generate also 5 similar queries that don't match the car completely. The negative queries should contain some of the real vehicle details\n",
    "but differ in some (some should be closer and some more different). The negative examples\n",
    "shouldn't be too absurd and fit to searches a second hand car dealer could have. They should be detailed. Include\n",
    "other details this car hasn't but are common for other cars. The negative queries should be close to the original car (and the true queries), but\n",
    "differ in a few important details.\n",
    "Make the negative queries multiple sentences long and detailed. Add enough details so the overall negative questions are similiar in length to the positive ones.\n",
    "\n",
    "Some queries should be longer and some should be shorter. Some should be more detailed than others. Also the writing style should differ slightly.\n",
    "This is true for the positive and negative queries. When there is already a question related to a detail, try to focus on another detail or use a synonym.\n",
    "\n",
    "To JSON:\n",
    "\n",
    "Please put the queries into a json item.\n",
    "Like this:\n",
    "{\n",
    "\"This is a matching query\": true,\n",
    "\"This is another matching query\": true,\n",
    "\"This is not a matching query\": false,\n",
    "}\n",
    "\n",
    "Only respond with the json item you created.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "url, yaml_text = list(vehicle_data.items())[4]\n",
    "user_prompt = yaml_text + question\n",
    "print(user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# This key has been deleted and is no longer active\n",
    "api_key = \"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\"\n",
    "\n",
    "client = openai.OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "updated_data = {}\n",
    "generated_question_file = \"../../data/generated_questions\"\n",
    "\n",
    "retries = 3\n",
    "save_interval = 40\n",
    "\n",
    "for idx, (url, yaml_text) in enumerate( vehicle_data.items(), start=1):\n",
    "    user_prompt = yaml_text + question\n",
    "    parsed_result = None\n",
    "\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ],\n",
    "                temperature=0.7\n",
    "            )\n",
    "\n",
    "            answer = response.choices[0].message.content.strip()\n",
    "\n",
    "            parsed = json.loads(answer)\n",
    "\n",
    "            # Validate structure: dict with 10 string:bool pairs\n",
    "            if (\n",
    "                isinstance(parsed, dict)\n",
    "                and len(parsed) == 10\n",
    "                and all(isinstance(k, str) and isinstance(v, bool) for k, v in parsed.items())\n",
    "            ):\n",
    "                parsed_result = parsed\n",
    "                break  # Success\n",
    "            else:\n",
    "                print(f\"[Attempt {attempt+1}] Invalid format or length for URL: {url}\")\n",
    "\n",
    "        except (json.JSONDecodeError, Exception) as e:\n",
    "            print(f\"[Attempt {attempt+1}] Error processing URL {url}: {e}\")\n",
    "\n",
    "    if parsed_result is not None:\n",
    "        updated_data[url] = parsed_result\n",
    "    else:\n",
    "        print(f\"Failed to process {url} after {retries} attempts.\")\n",
    "\n",
    "    # Periodic save in case of crash\n",
    "    if idx % save_interval == 0:\n",
    "        with open(f\"{generated_question_file}_{idx}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(updated_data, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"[Checkpoint] Saved progress at {idx} items.\")\n",
    "\n",
    "with open(generated_question_file + \".json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(updated_data, f, indent=2, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
